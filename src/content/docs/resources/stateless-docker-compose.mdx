---
title: Stateless Docker Compose
description: Docker Compose file for deploying Isekai with external managed services
---
import { Aside } from "@astrojs/starlight/components";

This Docker Compose configuration runs **only the application containers** (frontend, backend, publisher) and connects to **external managed services** for PostgreSQL and Redis. This is the recommended setup for:

- Production environments
- High-availability deployments
- Kubernetes or container orchestration platforms
- Environments with managed database services (AWS RDS, DigitalOcean, Neon, etc.)

<Aside type="tip">
Since no data is stored in containers, you can scale, update, or restart services without worrying about data loss.
</Aside>

## When to Use This Configuration

Use this configuration when:
- You have access to managed PostgreSQL and Redis services
- You need horizontal scaling (multiple backend/publisher instances)
- You want to separate compute from storage
- You're deploying in a high-availability environment

For simpler deployments or local installations, consider using the [Stateful Docker Compose](/resources/stateful-docker-compose) configuration instead.

## Configuration File

```yml
services:
  backend:
    image: ghcr.io/isekai-sh/isekai-backend:${IMAGE_TAG:-latest}
    container_name: isekai-backend
    ports:
      - "${BACKEND_PORT:-4000}:4000"
    environment:
      # Database & Cache (Must be set in .env)
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: ${REDIS_URL}

      # Application Config
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost:3000}
      PORT: 4000
      NODE_ENV: production

      # Security
      SESSION_SECRET: ${SESSION_SECRET}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY}
      COOKIE_DOMAIN: ${COOKIE_DOMAIN:-}
      SESSION_MAX_AGE_DAYS: ${SESSION_MAX_AGE_DAYS:-7}
      REFRESH_TOKEN_EXPIRY_DAYS: ${REFRESH_TOKEN_EXPIRY_DAYS:-90}

      # Integrations
      DEVIANTART_CLIENT_ID: ${DEVIANTART_CLIENT_ID}
      DEVIANTART_CLIENT_SECRET: ${DEVIANTART_CLIENT_SECRET}
      DEVIANTART_REDIRECT_URI: ${DEVIANTART_REDIRECT_URI}

      R2_ACCOUNT_ID: ${R2_ACCOUNT_ID}
      R2_ACCESS_KEY_ID: ${R2_ACCESS_KEY_ID}
      R2_SECRET_ACCESS_KEY: ${R2_SECRET_ACCESS_KEY}
      R2_BUCKET_NAME: ${R2_BUCKET_NAME:-isekai-uploads}
      R2_PUBLIC_URL: ${R2_PUBLIC_URL}

      SESSION_STORE: ${SESSION_STORE:-redis}
    env_file:
      - .env
    restart: always
    networks:
      - isekai-network
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:4000/api/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  publisher:
    image: ghcr.io/isekai-sh/isekai-publisher:${IMAGE_TAG:-latest}
    container_name: isekai-publisher
    ports:
      - "${PUBLISHER_HEALTH_PORT:-8000}:8000"
    environment:
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: ${REDIS_URL}
      NODE_ENV: production

      DEVIANTART_CLIENT_ID: ${DEVIANTART_CLIENT_ID}
      DEVIANTART_CLIENT_SECRET: ${DEVIANTART_CLIENT_SECRET}

      R2_ACCOUNT_ID: ${R2_ACCOUNT_ID}
      R2_ACCESS_KEY_ID: ${R2_ACCESS_KEY_ID}
      R2_SECRET_ACCESS_KEY: ${R2_SECRET_ACCESS_KEY}
      R2_BUCKET_NAME: ${R2_BUCKET_NAME:-isekai-uploads}
      R2_PUBLIC_URL: ${R2_PUBLIC_URL}

      # Publisher Tuning
      PUBLISHER_CONCURRENCY: ${PUBLISHER_CONCURRENCY:-5}
      PUBLISHER_MAX_ATTEMPTS: ${PUBLISHER_MAX_ATTEMPTS:-7}
      PUBLISHER_JOB_TIMEOUT_MS: ${PUBLISHER_JOB_TIMEOUT_MS:-600000}

      HEALTH_CHECK_PORT: 8000
      HEALTH_CHECK_ENABLED: true
    env_file:
      - .env
    restart: always
    networks:
      - isekai-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:8000/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    image: ghcr.io/isekai-sh/isekai-frontend:${IMAGE_TAG:-latest}
    container_name: isekai-frontend
    ports:
      - "${FRONTEND_PORT:-3000}:80"
    environment:
      VITE_API_URL: ${VITE_API_URL}
      VITE_DEVIANTART_CLIENT_ID: ${DEVIANTART_CLIENT_ID}
      VITE_R2_PUBLIC_URL: ${R2_PUBLIC_URL}
    env_file:
      - .env
    depends_on:
      - backend
    restart: always
    networks:
      - isekai-network
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:80/",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  isekai-network:
    driver: bridge
```

## Service Breakdown

### Backend (`backend`)
- **Image**: `ghcr.io/isekai-sh/isekai-backend`
- **Purpose**: API server, authentication, and job scheduling
- **External Dependencies**: Managed PostgreSQL and Redis
- **Port**: 4000 (configurable via `BACKEND_PORT`)

### Publisher (`publisher`)
- **Image**: `ghcr.io/isekai-sh/isekai-publisher`
- **Purpose**: Background worker for publishing to DeviantArt
- **External Dependencies**: Managed PostgreSQL and Redis
- **Port**: 8000 (health check endpoint)
- **Scaling**: Can run multiple instances for higher throughput

### Frontend (`frontend`)
- **Image**: `ghcr.io/isekai-sh/isekai-frontend`
- **Purpose**: User interface (React SPA)
- **Dependencies**: Backend API
- **Port**: 80 internally, mapped to 3000 externally (configurable via `FRONTEND_PORT`)

## Required Environment Variables

Since this configuration uses external services, you **must** provide connection strings in your `.env` file:

```bash
# External Database (REQUIRED)
DATABASE_URL="postgresql://user:password@your-db-host:5432/isekai?sslmode=require"

# External Redis (REQUIRED)
REDIS_URL="rediss://default:password@your-redis-host:6379"

# All other variables from the Environment Variables reference
# ...
```

<Aside type="caution">
**Connection Strings:** Ensure your DATABASE_URL and REDIS_URL point to your managed services. Use SSL/TLS connections (`sslmode=require` for PostgreSQL, `rediss://` for Redis) in production environments.
</Aside>

## Scaling Strategy

This configuration makes it easy to scale your deployment:

### Horizontal Scaling

- **Backend**: Scale to multiple instances behind a load balancer
- **Publisher**: Scale to process more jobs concurrently
- **Frontend**: Scale for high traffic (served via CDN recommended)

### Example with Docker Compose

```bash
# Scale publisher to 3 instances
docker compose up -d --scale publisher=3
```

<Aside type="tip">
For Kubernetes deployments, convert this Docker Compose file to Kubernetes manifests using tools like [Kompose](https://kompose.io/).
</Aside>
